{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import json\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import reuters\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: json.loads(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    db_path = '../data/DB.sqlite'\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    df_emails = pd.read_sql('SELECT * FROM Data', con=conn).drop('index', axis=1).reset_index(drop=True)\n",
    "    df_emails = load_json(df_emails)\n",
    "    \n",
    "    return df_emails\n",
    "\n",
    "\n",
    "def preprocess_mail_body(x):\n",
    "    mail_body =  x['Mail_1']\n",
    "    \n",
    "    if 'Mail_2' in x.keys():\n",
    "        mail_body = mail_body + ' ' + x['Mail_2']\n",
    "        \n",
    "    pattern_1 = re.compile(r'[\\w\\.-_]+@[\\w\\.-_]+')\n",
    "    \n",
    "    text = pattern_1.sub('', mail_body)\n",
    "    \n",
    "    pattern_2 = re.compile(r'(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+')\n",
    "    \n",
    "    text = pattern_2.sub('', text)\n",
    "    \n",
    "    text = ' '.join(word_tokenize(text))\n",
    "        \n",
    "    pattern_3 = re.compile(r'[^A-Za-z\\s]*')\n",
    "    \n",
    "    text = pattern_3.sub('', text)\n",
    "    \n",
    "#     text = ' '.join(x for x in text.split() if not any(c.isdigit() for c in x))\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    pattern_1 = re.compile(r'[^A-Za-z\\s]*')\n",
    "    text = pattern_1.sub('', text)\n",
    "#     text = ' '.join(x for x in text.split() if not any(c.isdigit() for c in x))\n",
    "    \n",
    "    text = text.lower()\n",
    "\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_email = load_data()\n",
    "\n",
    "cats_to_consider = cats_to_consider = ['1_Class_Add_Invoice', '2_Class_Payment_Query']\n",
    "\n",
    "df_email = df_email.loc[df_email.CLASS.isin(cats_to_consider)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4341, 15)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_email.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_email['BODY'] = df_email.BODY.apply(preprocess_mail_body)\n",
    "\n",
    "df_email['text'] = df_email.SUBJECT + ' ' + df_email.BODY\n",
    "\n",
    "df_email['text_tokens'] = df_email.text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    [adam, po, please, process, the, attached, inv...\n",
       "21    [adp, invoice, please, process, the, attached,...\n",
       "22    [brownstein, inv, please, process, the, attach...\n",
       "23    [c, anon, po, amerihealth, caritas, newarkfebr...\n",
       "24           [canon, performcare, bedfordfebruary, xls]\n",
       "Name: text_tokens, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_email.text_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_documents, train_categories = zip(\n",
    "        *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
    "    test_documents, test_categories = zip(\n",
    "        *[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])\n",
    "\n",
    "    return train_documents, train_categories, test_documents, test_categories\n",
    "\n",
    "\n",
    "train_documents, train_categories, test_documents, test_categories = load_data()\n",
    "\n",
    "df_train = pd.DataFrame({'Document': train_documents, 'Category': [x[0] for x in train_categories]})\n",
    "df_test = pd.DataFrame({'Document': test_documents, 'Category': [x[0] for x in test_categories]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df_train.Document.append(df_test.Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10788,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_model = Word2Vec(sentences=all_data.values.tolist(), iter=5, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('steers', 0.8733002543449402),\n",
       " ('experiencing', 0.8558189868927002),\n",
       " ('landed', 0.8551946878433228),\n",
       " ('bean', 0.8502511978149414),\n",
       " ('potatoes', 0.8498648405075073),\n",
       " ('destroying', 0.849547803401947),\n",
       " ('varieties', 0.8483351469039917),\n",
       " ('hrw', 0.8461303114891052),\n",
       " ('seeds', 0.8440544605255127),\n",
       " ('rye', 0.8425315618515015)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_model.most_similar('pig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
